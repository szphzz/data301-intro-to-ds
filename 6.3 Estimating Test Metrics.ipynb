{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Copy of 6.3 Estimating Test Metrics.ipynb","provenance":[{"file_id":"https://github.com/dlsun/pods/blob/master/06-Classification-Models/6.3%20Estimating%20Test%20Metrics.ipynb","timestamp":1653705670309}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"uLq7mGD6kjMd"},"source":["# 6.3 Estimating Test Metrics"]},{"cell_type":"markdown","metadata":{"id":"XmKrVx3pkjMl"},"source":["In the previous lesson, we learned several scores (accuracy, precision, recall, F1) for evaluating classification models. We calculated these scores on the training data---that is, the same data that was used to evaluate the model. In Chapter 5, we saw that evaluating machine learning models on the training data is problematic because a machine learning model can achieve a good training score by _overfitting_ to the training data. We argued that the goal of a machine learning model should be to achieve a good score on test data. (Chapter 5.4) However, ground truth labels are often not available for the test data. Nevertheless, we can use cross-validation on the training data to estimate the test scores. (Chapter 5.5) These so-called _validation scores_ can be used to select between models and tune hyperparameters. (Chapter 5.6)\n","\n","Although Chapter 5 was about regression models, the exact same program can be carried out for classification models. Instead of calculating the *training* accuracy, precision, etc., we estimate the *test* accuracy, precision, etc. using cross-validation. This lesson demonstrates how to carry out this program, but the concepts (and even the code) are essentially identical to Chapter 5.\n","\n","First, we define a classifier that we want to evaluate."]},{"cell_type":"code","metadata":{"id":"WCtQkyAokjMn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654134704553,"user_tz":420,"elapsed":3811,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"0b739c28-ac81-43a4-c75f-d7c6087f19b0"},"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import make_pipeline\n","\n","data_dir = \"http://dlsun.github.io/pods/data/\"\n","df_breast = pd.read_csv(data_dir + \"breast-cancer.csv\")\n","\n","X_train = df_breast[[\"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\",\n","                     \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nuclei\",\n","                     \"Bland Chromatin\", \"Normal Nucleoli\", \"Mitoses\"]]\n","y_train = df_breast[\"Class\"]\n","\n","pipeline = make_pipeline(\n","    StandardScaler(),\n","    KNeighborsClassifier(n_neighbors=10)\n",")\n","\n","pipeline.fit(X=X_train, y=y_train)"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('standardscaler', StandardScaler()),\n","                ('kneighborsclassifier', KNeighborsClassifier(n_neighbors=10))])"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"KzRWgQ7qkjMy"},"source":["To calculate test scores using $k$-fold cross validation, we use the `cross_val_score` function in scikit-learn. For example, to calculate test accuracy, we do the following:"]},{"cell_type":"code","metadata":{"id":"UJ4TfB4SkjM1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654134704899,"user_tz":420,"elapsed":357,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"d208c887-bc8c-49ae-e1c1-fc18c3db9a46"},"source":["from sklearn.model_selection import cross_val_score\n","\n","cv_scores = cross_val_score(pipeline, X_train, y_train, \n","                            cv=10, scoring=\"accuracy\")\n","cv_scores"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.89855072, 0.95652174, 0.95652174, 0.94117647, 0.98529412,\n","       0.95588235, 0.97058824, 0.98529412, 0.98529412, 1.        ])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"8891bSQPkjM6"},"source":["We get 10 accuracy scores, one from each of the $k=10$ folds. It is customary to average these accuracy scores to obtain one overall estimate of the test accuracy."]},{"cell_type":"code","metadata":{"id":"4lzoByBGkjM8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654134704899,"user_tz":420,"elapsed":7,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"38bf9b71-a192-4840-ddb2-1c884bede8f0"},"source":["cv_scores.mean()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9635123614663257"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"gghNK3x3kjNC"},"source":["This validation accuracy is high, but lower than the 97.2% training accuracy that we obtained in the previous lesson. This makes sense because it is always harder for a model to predict on data it has not seen than on data it saw. Recall that Wenger's neural network model that won the Google Science Fair had an accuracy of 97.4%. We have come close to achieving that using a simple $10$-nearest neighbors classifier."]},{"cell_type":"markdown","metadata":{"id":"rlHU2vkMkjNF"},"source":["Scikit-Learn can also calculate the precision and recall of a class $c$, but the labels need to be converted to a binary label that is $1$ (or `True`) if the observation is in class $c$ and $0$ (or `False`) otherwise. For example, to calculate the precision for benign tumors (class 0), we define the new label `is_benign`."]},{"cell_type":"code","metadata":{"id":"oFe5IG5ukjNN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654134705212,"user_tz":420,"elapsed":318,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"3a6d69f6-e8c7-4995-d4aa-86ded741d781"},"source":["is_benign = (y_train == 0)\n","\n","cross_val_score(pipeline, X_train, is_benign, \n","                cv=10, scoring=\"precision\").mean()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9779051122632646"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"JjpoZ8iVkjNf"},"source":["To calculate the validation _recall_ for benign tumors, we simply change the scoring method:"]},{"cell_type":"code","metadata":{"id":"wJc9Gy45kjNh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654134705945,"user_tz":420,"elapsed":735,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"90753cb6-b1d6-4b0f-a1c2-c671b2e3e677"},"source":["cross_val_score(pipeline, X_train, is_benign, \n","                cv=10, scoring=\"recall\").mean()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9754040404040405"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"R9kzEeuVkjN1"},"source":["Likewise, the validation precision and recall for malignant tumors is "]},{"cell_type":"code","metadata":{"id":"X29ZE0KekjN4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654134706941,"user_tz":420,"elapsed":1000,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"19f9b18b-0a51-49fa-f58d-ba5abe0ec9d7"},"source":["is_malignant = (y_train == 1)\n","\n","precision = cross_val_score(pipeline, X_train, is_malignant, \n","                            cv=10, scoring=\"precision\").mean()\n","recall = cross_val_score(pipeline, X_train, is_malignant, \n","                         cv=10, scoring=\"recall\").mean()\n","\n","precision, recall"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.9590172532781228, 0.9373188405797102)"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"AkLKAD4fkjN9"},"source":["Another term for recall is _sensitivity_. Wenger's model was 99.1% sensitive to malignancy; our model is quite a bit worse, achieving a sensitivity (i.e., recall) of only 93.7%."]},{"cell_type":"markdown","metadata":{"id":"rlfLbhqWkjN-"},"source":["## Hyperparameter Tuning\n","\n","Could we do better with a different value of $k$? We can use cross-validation on a grid of $k$ values and pick the one that maximizes some score. Since the F1 score summarizes both precision and recall, we use F1 as the score. There are two F1 scores---one for the benign masses and the malignant masses---`_macro` specifies that we take the average."]},{"cell_type":"code","metadata":{"id":"ULyEVdT1kjN_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654134718751,"user_tz":420,"elapsed":11813,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"91a69571-c5bd-48a4-d2ba-623657fc0f22"},"source":["from sklearn.model_selection import GridSearchCV\n","\n","grid_search = GridSearchCV(\n","    pipeline,\n","    param_grid={\"kneighborsclassifier__n_neighbors\": range(1, 50)},\n","    scoring=\"f1_macro\",\n","    cv=10\n",")\n","\n","grid_search.fit(X_train, y_train)\n","grid_search.best_params_"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'kneighborsclassifier__n_neighbors': 13}"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"F6uXKGD6kjOM"},"source":["Is this value of $k$ better? It certainly has a higher average F1 score. What about its precision and recall for malignant masses?"]},{"cell_type":"code","metadata":{"id":"d_PygmI0kjOP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654134719524,"user_tz":420,"elapsed":783,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"b3c19c46-c84d-49bc-e00a-044540f21ed2"},"source":["new_precision = cross_val_score(\n","    grid_search.best_estimator_,\n","    X_train, is_malignant,\n","    scoring=\"precision\",\n","    cv=10).mean()\n","\n","new_recall = cross_val_score(\n","    grid_search.best_estimator_,\n","    X_train, is_malignant,\n","    scoring=\"recall\",\n","    cv=10).mean()\n","\n","precision, new_precision, recall, new_recall"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.9590172532781228, 0.9640265700483092, 0.9373188405797102, 0.953985507246377)"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"3qslknI2kjOW"},"source":["We see that the new model has a higher precision _and_ a higher recall for malignancy. This suggests that the new model is unambiguously better. (If only recall had been higher, then it could be argued that we were simply trading off precision for recall.)"]},{"cell_type":"markdown","metadata":{"id":"_Iu-iEBokjOY"},"source":["# Exercises\n","\n","Exercises 1-2 ask you to use the Titanic data set (`https://dlsun.github.io/pods/data/titanic.csv`)."]},{"cell_type":"code","source":["titanic = pd.read_csv(\"https://dlsun.github.io/pods/data/titanic.csv\")\n","titanic.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Gj8RzHyHHLj-","executionInfo":{"status":"ok","timestamp":1654134736777,"user_tz":420,"elapsed":781,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"c08ddeda-b208-41d9-e11f-0e96ad4bb33d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             name  gender   age class embarked        country  \\\n","0             Abbing, Mr. Anthony    male  42.0   3rd        S  United States   \n","1       Abbott, Mr. Eugene Joseph    male  13.0   3rd        S  United States   \n","2     Abbott, Mr. Rossmore Edward    male  16.0   3rd        S  United States   \n","3  Abbott, Mrs. Rhoda Mary 'Rosa'  female  39.0   3rd        S        England   \n","4     Abelseth, Miss. Karen Marie  female  16.0   3rd        S         Norway   \n","\n","   ticketno   fare  survived  \n","0    5547.0   7.11         0  \n","1    2673.0  20.05         0  \n","2    2673.0  20.05         0  \n","3    2673.0  20.05         1  \n","4  348125.0   7.13         1  "],"text/html":["\n","  <div id=\"df-fd189dcf-fc78-4931-970c-472a36796780\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>gender</th>\n","      <th>age</th>\n","      <th>class</th>\n","      <th>embarked</th>\n","      <th>country</th>\n","      <th>ticketno</th>\n","      <th>fare</th>\n","      <th>survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Abbing, Mr. Anthony</td>\n","      <td>male</td>\n","      <td>42.0</td>\n","      <td>3rd</td>\n","      <td>S</td>\n","      <td>United States</td>\n","      <td>5547.0</td>\n","      <td>7.11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Abbott, Mr. Eugene Joseph</td>\n","      <td>male</td>\n","      <td>13.0</td>\n","      <td>3rd</td>\n","      <td>S</td>\n","      <td>United States</td>\n","      <td>2673.0</td>\n","      <td>20.05</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Abbott, Mr. Rossmore Edward</td>\n","      <td>male</td>\n","      <td>16.0</td>\n","      <td>3rd</td>\n","      <td>S</td>\n","      <td>United States</td>\n","      <td>2673.0</td>\n","      <td>20.05</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Abbott, Mrs. Rhoda Mary 'Rosa'</td>\n","      <td>female</td>\n","      <td>39.0</td>\n","      <td>3rd</td>\n","      <td>S</td>\n","      <td>England</td>\n","      <td>2673.0</td>\n","      <td>20.05</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Abelseth, Miss. Karen Marie</td>\n","      <td>female</td>\n","      <td>16.0</td>\n","      <td>3rd</td>\n","      <td>S</td>\n","      <td>Norway</td>\n","      <td>348125.0</td>\n","      <td>7.13</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd189dcf-fc78-4931-970c-472a36796780')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fd189dcf-fc78-4931-970c-472a36796780 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fd189dcf-fc78-4931-970c-472a36796780');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["titanic = titanic[~titanic[\"age\"].isna()]"],"metadata":{"id":"FMEmq8hpHSD9","executionInfo":{"status":"ok","timestamp":1654134760493,"user_tz":420,"elapsed":1,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ThXrjLY5kjOZ"},"source":["1\\. Train a 5-nearest neighbors model to predict whether or not a passenger on a Titanic survived, using their age, sex, and class as features. Estimate the test accuracy, precision, and recall of this model for the survivors and the deceased."]},{"cell_type":"code","source":["X_train = titanic[[\"age\", \"gender\", \"class\"]]\n","y_train = titanic[\"survived\"]"],"metadata":{"id":"QldnlIM2HYsE","executionInfo":{"status":"ok","timestamp":1654134797318,"user_tz":420,"elapsed":261,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from sklearn.compose import make_column_transformer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.pipeline import make_pipeline\n","\n","ct = make_column_transformer(\n","    (OneHotEncoder(), [\"gender\", \"class\"]),\n","    (StandardScaler(), [\"age\"]),\n","    remainder=\"drop\"\n",")\n","\n","pipeline = make_pipeline(\n","    ct,\n","    KNeighborsClassifier(n_neighbors=5)\n",")"],"metadata":{"id":"pOvfS14gHf3s","executionInfo":{"status":"ok","timestamp":1654134904053,"user_tz":420,"elapsed":5,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["cross_val_score(pipeline, X_train, y_train,\n","                cv=10, scoring=\"accuracy\").mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RbwiNXNH548","executionInfo":{"status":"ok","timestamp":1654134960917,"user_tz":420,"elapsed":601,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"0e8cca89-cf5d-4011-9997-49553a5b5c83"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7718634306869602"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["cross_val_score(pipeline, X_train, y_train,\n","                cv=10, scoring=\"precision\").mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEer46eRICK0","executionInfo":{"status":"ok","timestamp":1654134961607,"user_tz":420,"elapsed":273,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"d31c0a9f-5b2d-4d30-d3ff-41a9d051c688"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6946814139064579"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["cross_val_score(pipeline, X_train, y_train,\n","                cv=10, scoring=\"recall\").mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8hB-s5dpICaN","executionInfo":{"status":"ok","timestamp":1654134963270,"user_tz":420,"elapsed":399,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"edadc502-5f32-4fb1-bb20-6352cb550ec8"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5373239436619718"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"hFDd1tF7kjOa"},"source":["2\\. You want to build a $k$-nearest neighbors model to predict whether or not a passenger on the Titanic survived, using their age, sex, and class. \n","\n","- What value of $k$ optimizes overall accuracy?\n","- What value of $k$ optimizes the F1 score for the deceased?\n","\n","Does the same value of $k$ optimize accuracy and the F1 score?"]},{"cell_type":"code","source":["grid_search = GridSearchCV(\n","    pipeline,\n","    param_grid={\"kneighborsclassifier__n_neighbors\": range(1, 50)},\n","    scoring=\"accuracy\",\n","    cv=10\n",")\n","\n","grid_search.fit(X_train, y_train)\n","grid_search.best_params_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbWR3-j1HQ4U","executionInfo":{"status":"ok","timestamp":1654135058289,"user_tz":420,"elapsed":12670,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"8e825983-025c-47da-810c-104afa74947c"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'kneighborsclassifier__n_neighbors': 13}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, make_scorer\n","\n","grid_search = GridSearchCV(\n","    pipeline,\n","    param_grid={\"kneighborsclassifier__n_neighbors\": range(1, 50)},\n","    scoring=make_scorer(f1_score, pos_label=1),\n","    cv=10\n",")\n","\n","grid_search.fit(X_train, y_train)\n","grid_search.best_params_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OJSkvtnIZwX","executionInfo":{"status":"ok","timestamp":1654135532393,"user_tz":420,"elapsed":15737,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"59d20f51-5641-4084-b75e-cb7082b68941"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'kneighborsclassifier__n_neighbors': 13}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["**My analysis concludes that the same value of k optimizes both accuracy and the F1 score.**"],"metadata":{"id":"p_YXnEHPKP_P"}}]}