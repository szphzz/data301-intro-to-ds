{"cells":[{"cell_type":"markdown","metadata":{"id":"PLSgTzfGr_pt"},"source":["# 5.5 Estimating the Test Error\n","\n","In the previous lesson, we learned about _training error_, which is the error calculated on the training data. Training error is easy to calculate because the true labels are available in the training data. However, training error is not always a good measure of a model's quality, since a model that _overfits_ to the training data may have artificially low training error.\n","\n","Ideally, we would like to evaluate regression models based on their _test error_, which is the error calculated on the test data. The problem with test error is that it is usually impossible to calculate, since the true labels are rarely available in the test data. In this section, we discuss strategies for estimating the test error using only the training data."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"CRHMJ2usr_px","executionInfo":{"status":"ok","timestamp":1653525803570,"user_tz":420,"elapsed":947,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# Extract the training data.\n","data_dir = \"https://dlsun.github.io/pods/data/\"\n","bordeaux_df = pd.read_csv(data_dir + \"bordeaux.csv\",\n","                          index_col=\"year\")\n","bordeaux_train = bordeaux_df.loc[:1980].copy()\n","bordeaux_train[\"log(price)\"] = np.log(bordeaux_train[\"price\"])"]},{"cell_type":"markdown","metadata":{"id":"IJ6e741dr_pz"},"source":["## Validation Error\n","\n","To estimate the test error, we split the training data into a _training set_ and a _validation set_. First, the model is fit to just the data in the training set. Then, the model is evaluated based on its predictions on the validation set. Because the model did not train on any of the labels in the validation set, the validation set essentially plays the role of the test data, even though it was carved out of the training data.\n","\n","The prediction error on the validation set is known as the _validation error_. The validation error is an approximation to the test error."]},{"cell_type":"markdown","metadata":{"id":"iOaf6Kb8r_p0"},"source":["To split our data into training and validation sets, we can use the `.sample()` function in `pandas`. Let's use this to split our data into two equal halves, which we will call `train` and `val`."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"rmXqLTs7r_p0","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"ok","timestamp":1653525803571,"user_tz":420,"elapsed":7,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"e75d79d9-364f-42b2-c1ba-a5ec11ee26de"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      price  summer  har   sep  win  age  log(price)\n","year                                                \n","1970   40.0    16.7   89  18.0  622   22    3.688879\n","1955   45.0    17.1  130  16.8  502   37    3.806662\n","1961  100.0    17.3   38  20.4  830   31    4.605170\n","1976   25.0    17.6  247  16.1  418   16    3.218876\n","1968   11.0    16.2  292  16.4  610   24    2.397895\n","1977   11.0    15.6   87  16.8  821   15    2.397895\n","1952   37.0    17.1  160  14.3  600   40    3.610918\n","1972   10.0    15.0  158  14.6  536   20    2.302585\n","1953   63.0    16.7   80  17.3  690   39    4.143135\n","1978   27.0    15.8   51  17.4  763   14    3.295837\n","1969   12.0    16.5  244  16.6  575   23    2.484907\n","1967   19.0    16.2  118  16.5  714   25    2.944439\n","1962   33.0    16.3   52  17.2  697   30    3.496508\n","1971   27.0    16.8  112  16.9  551   21    3.295837"],"text/html":["\n","  <div id=\"df-18921cc5-6145-4d53-8b4f-f691bf87f958\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>price</th>\n","      <th>summer</th>\n","      <th>har</th>\n","      <th>sep</th>\n","      <th>win</th>\n","      <th>age</th>\n","      <th>log(price)</th>\n","    </tr>\n","    <tr>\n","      <th>year</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1970</th>\n","      <td>40.0</td>\n","      <td>16.7</td>\n","      <td>89</td>\n","      <td>18.0</td>\n","      <td>622</td>\n","      <td>22</td>\n","      <td>3.688879</td>\n","    </tr>\n","    <tr>\n","      <th>1955</th>\n","      <td>45.0</td>\n","      <td>17.1</td>\n","      <td>130</td>\n","      <td>16.8</td>\n","      <td>502</td>\n","      <td>37</td>\n","      <td>3.806662</td>\n","    </tr>\n","    <tr>\n","      <th>1961</th>\n","      <td>100.0</td>\n","      <td>17.3</td>\n","      <td>38</td>\n","      <td>20.4</td>\n","      <td>830</td>\n","      <td>31</td>\n","      <td>4.605170</td>\n","    </tr>\n","    <tr>\n","      <th>1976</th>\n","      <td>25.0</td>\n","      <td>17.6</td>\n","      <td>247</td>\n","      <td>16.1</td>\n","      <td>418</td>\n","      <td>16</td>\n","      <td>3.218876</td>\n","    </tr>\n","    <tr>\n","      <th>1968</th>\n","      <td>11.0</td>\n","      <td>16.2</td>\n","      <td>292</td>\n","      <td>16.4</td>\n","      <td>610</td>\n","      <td>24</td>\n","      <td>2.397895</td>\n","    </tr>\n","    <tr>\n","      <th>1977</th>\n","      <td>11.0</td>\n","      <td>15.6</td>\n","      <td>87</td>\n","      <td>16.8</td>\n","      <td>821</td>\n","      <td>15</td>\n","      <td>2.397895</td>\n","    </tr>\n","    <tr>\n","      <th>1952</th>\n","      <td>37.0</td>\n","      <td>17.1</td>\n","      <td>160</td>\n","      <td>14.3</td>\n","      <td>600</td>\n","      <td>40</td>\n","      <td>3.610918</td>\n","    </tr>\n","    <tr>\n","      <th>1972</th>\n","      <td>10.0</td>\n","      <td>15.0</td>\n","      <td>158</td>\n","      <td>14.6</td>\n","      <td>536</td>\n","      <td>20</td>\n","      <td>2.302585</td>\n","    </tr>\n","    <tr>\n","      <th>1953</th>\n","      <td>63.0</td>\n","      <td>16.7</td>\n","      <td>80</td>\n","      <td>17.3</td>\n","      <td>690</td>\n","      <td>39</td>\n","      <td>4.143135</td>\n","    </tr>\n","    <tr>\n","      <th>1978</th>\n","      <td>27.0</td>\n","      <td>15.8</td>\n","      <td>51</td>\n","      <td>17.4</td>\n","      <td>763</td>\n","      <td>14</td>\n","      <td>3.295837</td>\n","    </tr>\n","    <tr>\n","      <th>1969</th>\n","      <td>12.0</td>\n","      <td>16.5</td>\n","      <td>244</td>\n","      <td>16.6</td>\n","      <td>575</td>\n","      <td>23</td>\n","      <td>2.484907</td>\n","    </tr>\n","    <tr>\n","      <th>1967</th>\n","      <td>19.0</td>\n","      <td>16.2</td>\n","      <td>118</td>\n","      <td>16.5</td>\n","      <td>714</td>\n","      <td>25</td>\n","      <td>2.944439</td>\n","    </tr>\n","    <tr>\n","      <th>1962</th>\n","      <td>33.0</td>\n","      <td>16.3</td>\n","      <td>52</td>\n","      <td>17.2</td>\n","      <td>697</td>\n","      <td>30</td>\n","      <td>3.496508</td>\n","    </tr>\n","    <tr>\n","      <th>1971</th>\n","      <td>27.0</td>\n","      <td>16.8</td>\n","      <td>112</td>\n","      <td>16.9</td>\n","      <td>551</td>\n","      <td>21</td>\n","      <td>3.295837</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18921cc5-6145-4d53-8b4f-f691bf87f958')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-18921cc5-6145-4d53-8b4f-f691bf87f958 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-18921cc5-6145-4d53-8b4f-f691bf87f958');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}],"source":["train = bordeaux_train.sample(frac=.5)\n","val = bordeaux_train.drop(train.index)\n","\n","train"]},{"cell_type":"markdown","metadata":{"id":"XrGLYK8zr_p1"},"source":["Now let's use these training/validation sets to approximate the test MSE of the 5-nearest neighbors model that we fit in Chapter 5.2."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3NFAXekQr_p1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525804985,"user_tz":420,"elapsed":1418,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"fc3dd77b-a1d4-4374-fe6f-b7a6addc29da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('standardscaler', StandardScaler()),\n","                ('kneighborsregressor', KNeighborsRegressor())])"]},"metadata":{},"execution_count":3}],"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.pipeline import make_pipeline\n","\n","# extract features and label from training set\n","X_train = train[[\"win\", \"summer\"]]\n","y_train = train[\"log(price)\"]\n","\n","# define pipeline and fit to training set\n","pipeline = make_pipeline(\n","          StandardScaler(),\n","          KNeighborsRegressor(n_neighbors=5)\n",")\n","pipeline.fit(X=X_train, y=y_train)"]},{"cell_type":"markdown","metadata":{"id":"V-uSy6HSr_p3"},"source":["We make predictions on the validation set and calculate the validation RMSE:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"eLx6VMQsr_p3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525805177,"user_tz":420,"elapsed":196,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"a1be67a2-0d9b-48d9-8943-8238785790fa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.44169569869735253"]},"metadata":{},"execution_count":4}],"source":["from sklearn.metrics import mean_squared_error\n","\n","# extract features and label from validation set\n","X_val = val[[\"win\", \"summer\"]]\n","y_val = val[\"log(price)\"]\n","\n","# get model's predictions on validation set\n","y_val_ = pipeline.predict(X_val)\n","\n","# calculate RMSE on validation set\n","rmse = np.sqrt(mean_squared_error(y_val, y_val_))\n","rmse"]},{"cell_type":"markdown","metadata":{"id":"StteL-yrr_p4"},"source":["Notice that the test error is higher than the training error that we calculated in the previous lesson. In general, this will be true. It is harder for a model to predict for new observations it has not seen, than for observations it has seen!"]},{"cell_type":"markdown","metadata":{"id":"SXc25E3Er_p4"},"source":["## Cross Validation\n","\n","The validation error above was calculated using only 50% of the training data, since we split the training data in half to create the validation set. As a result, the estimate is noisy.\n","\n","There is a cheap way to obtain a second opinion about how well our model will do on future data. Previously, we split our data at random into two halves, fitting the model to the first half and evaluating it on the second half. Because the model has not already seen the second half of the data, this approximates how well the model would perform on future data. \n","\n","But the way we split our data was arbitrary. We might as well swap the roles of the two halves, fitting the model to the _second_ half and evaluating it on the _first_ half. As long as the model is always evaluated on data that is different from the data that was used to train it, we have a valid estimate of test error. A schematic of this approach, known as _cross-validation_, is shown below.\n","\n","![](https://github.com/dlsun/pods/blob/master/05-Regression-Models/cross-validation.png?raw=1)\n","\n","Because we will be doing all computations twice, just with different data, let's wrap the $k$-nearest neighbors algorithm above into a function called `get_val_error()`, that computes the validation error given training and validation data."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"zc73m5dXr_p5","executionInfo":{"status":"ok","timestamp":1653525806857,"user_tz":420,"elapsed":192,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"outputs":[],"source":["def get_val_error(train, val):\n","    \n","    # extract features and label from training set.\n","    X_train = train[[\"win\", \"summer\"]]\n","    y_train = train[\"log(price)\"]\n","    \n","    # eefine pipeline and fit to training set\n","    pipeline = make_pipeline(\n","          StandardScaler(),\n","          KNeighborsRegressor(n_neighbors=5)\n","    )\n","    pipeline.fit(X=X_train, y=y_train)\n","    \n","    # extract features and label from validation set\n","    X_val = val[[\"win\", \"summer\"]]\n","    y_val = val[\"log(price)\"]\n","    \n","    # get model's predictions on validation set\n","    y_val_ = pipeline.predict(X_val)\n","\n","    # calculate RMSE on validation set\n","    rmse = np.sqrt(mean_squared_error(y_val, y_val_))\n","    \n","    return rmse"]},{"cell_type":"markdown","metadata":{"id":"toQ5Inrwr_p6"},"source":["If we apply this function to the training and validation sets from earlier, we get the same estimate of the test error."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"25a562Ekr_p6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525808742,"user_tz":420,"elapsed":130,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"9b46f84d-21cf-4dc3-c77f-345208e898d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.44169569869735253"]},"metadata":{},"execution_count":6}],"source":["get_val_error(train, val)"]},{"cell_type":"markdown","metadata":{"id":"alFeJ1qFr_p6"},"source":["But if we reverse the roles of the training and validation sets, we get another estimate of the test error."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lETVfAk2r_p6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525809902,"user_tz":420,"elapsed":128,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"5114d2a6-06a4-4c8c-b696-e38495643595"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6103419219176969"]},"metadata":{},"execution_count":7}],"source":["get_val_error(val, train)"]},{"cell_type":"markdown","metadata":{"id":"LE3ESzUvr_p7"},"source":["Now we have two, somewhat independent estimates of the test error. It is common to average the two numbers to obtain an overall estimate of the test error, called the _cross-validation estimate of test error_. Notice that the cross-validation estimate uses each observation in the data exactly once. We make a prediction for each observation, but always using a model that was trained on data that does not include that observation."]},{"cell_type":"markdown","metadata":{"id":"KFgCZPoQr_p7"},"source":["## Cross-Validation in scikit-learn\n","\n","As you know by now, scikit-learn provides functions that automate routine tasks of machine learning. For cross-validation, there is a function, `cross_val_score`, that takes in a model (or pipeline), the training data, and a scoring function, and carries out all aspects of cross-validation, including\n","\n","1. splitting the training data into training and validation sets\n","2. fitting the model to each training set\n","3. calculating the model's predictions on the corresponding validation set\n","4. calculating the score of the predictions on each validation set."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"j4ArcrXgr_p7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525812084,"user_tz":420,"elapsed":154,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"d941c780-01df-422b-c714-84e93fde89ce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.47767636, -0.38655855])"]},"metadata":{},"execution_count":8}],"source":["from sklearn.model_selection import cross_val_score\n","\n","scores = cross_val_score(pipeline, \n","                         X=bordeaux_train[[\"win\", \"summer\"]],\n","                         y=bordeaux_train[\"log(price)\"],\n","                         scoring=\"neg_mean_squared_error\",\n","                         cv=2)\n","scores"]},{"cell_type":"markdown","metadata":{"id":"hlnnFh_rr_p8"},"source":["First, notice that there are 2 scores. This is because scikit-learn calculated a score from each half of the data when that half served as the validation set.\n","\n","Second, observe that the scores are negative. This is because scikit-learn requires that a \"score\" be something that ought to be maximized. Since we want to minimize the mean-squared error, we want to maximize the *negative* mean-squared error. Therefore, the scores that are reported here are the negative of the MSE.\n","\n","To calculate the RMSE, we negate the negative sign and take a square root."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"afcmhlyQr_p8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525813489,"user_tz":420,"elapsed":136,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"b60c0bee-fa57-4a45-e993-c18af8aefef2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.69114134, 0.62173833])"]},"metadata":{},"execution_count":9}],"source":["np.sqrt(-scores)"]},{"cell_type":"markdown","metadata":{"id":"WEQhfVOkr_p8"},"source":["The average of these two scores is the cross-validation estimate of test error."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"dDTLQ15Jr_p8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525814695,"user_tz":420,"elapsed":147,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"7c0be2d4-ab16-4fdc-fb70-31c2c04cb0f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6564398373317621"]},"metadata":{},"execution_count":10}],"source":["np.sqrt(-scores).mean()"]},{"cell_type":"markdown","metadata":{"id":"6teUO2uWr_p9"},"source":["## $K$-Fold Cross Validation\n","\n","One problem with splitting the training data into two halves is that the model is now trained on only half the amount of data. This model will likely perform worse than the actual model, which is trained on all of the training data. So the cross-validation estimate of test error is unnecessarily pessimistic.\n","\n","We would like the size of the training set to be closer to the size of the original training data. We can do this by splitting the data into more than two subsamples. In general, we can split the data into $k$ subsamples, alternately training the data on $k-1$ subsamples and evaluating the model on the $1$ remaining subsample, i.e., the validation set. This produces $k$ somewhat independent estimates of the test error. This procedure is known as **$k$-fold cross validation**. (Be careful not to confuse this $k$ with the $k$ in $k$-nearest neighbors.) In hindsight, the  cross validation that we were doing previously is $2$-fold cross validation.\n","\n","A schematic of $4$-fold cross validation is shown below.\n","\n","![](https://github.com/dlsun/pods/blob/master/05-Regression-Models/k-folds.png?raw=1)\n","\n","Implementing $k$-fold cross validation in scikit-learn is easy. We simply set the `cv=` parameter to the desired number of folds. For example, the following code carries out $4$-fold cross validation."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"qjurHEasr_p9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525816868,"user_tz":420,"elapsed":413,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"72e10cae-6123-419d-aab6-6443bddf20b0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.47213584, -0.30601689, -0.36874833, -0.11290777])"]},"metadata":{},"execution_count":11}],"source":["scores = cross_val_score(pipeline, \n","                         X=bordeaux_train[[\"win\", \"summer\"]],\n","                         y=bordeaux_train[\"log(price)\"],\n","                         scoring=\"neg_mean_squared_error\",\n","                         cv=4)\n","scores"]},{"cell_type":"markdown","metadata":{"id":"e2-eYKZDr_p9"},"source":["Notice that $k$ scores are produced, one from each fold. These scores can be averaged to produce a single estimate of the test error."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"R_HyZT1Ur_p9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525818131,"user_tz":420,"elapsed":117,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"0e31f132-f129-4fdc-8c24-1a09713d2947"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.545893343925109"]},"metadata":{},"execution_count":12}],"source":["np.sqrt(-scores).mean()"]},{"cell_type":"markdown","metadata":{"id":"kT69yfZgr_p9"},"source":["# Exercises"]},{"cell_type":"markdown","metadata":{"id":"HydtFKNbr_p-"},"source":["1\\. Use cross-validation to approximate the *test* $R^2$ of the $10$-nearest neighbors regression model that we fit in the lesson of Chapter 5.3 to the Ames housing data set (http://dlsun.github.io/pods/data/AmesHousing.txt )."]},{"cell_type":"code","source":["ames = pd.read_table(\"http://dlsun.github.io/pods/data/AmesHousing.txt\")\n","ames.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"6ctdjjFn0bLm","executionInfo":{"status":"ok","timestamp":1653525849781,"user_tz":420,"elapsed":493,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"6b6f9888-b87a-4d03-dd9a-3903375a2e79"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n","0      1  526301100           20        RL         141.0     31770   Pave   \n","1      2  526350040           20        RH          80.0     11622   Pave   \n","2      3  526351010           20        RL          81.0     14267   Pave   \n","3      4  526353030           20        RL          93.0     11160   Pave   \n","4      5  527105010           60        RL          74.0     13830   Pave   \n","\n","  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n","0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n","1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n","2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n","3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n","4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n","\n","  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n","0        0       5    2010       WD           Normal     215000  \n","1        0       6    2010       WD           Normal     105000  \n","2    12500       6    2010       WD           Normal     172000  \n","3        0       4    2010       WD           Normal     244000  \n","4        0       3    2010       WD           Normal     189900  \n","\n","[5 rows x 82 columns]"],"text/html":["\n","  <div id=\"df-90fe20a4-35ad-4843-9fc8-e7721d0eb239\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Order</th>\n","      <th>PID</th>\n","      <th>MS SubClass</th>\n","      <th>MS Zoning</th>\n","      <th>Lot Frontage</th>\n","      <th>Lot Area</th>\n","      <th>Street</th>\n","      <th>Alley</th>\n","      <th>Lot Shape</th>\n","      <th>Land Contour</th>\n","      <th>...</th>\n","      <th>Pool Area</th>\n","      <th>Pool QC</th>\n","      <th>Fence</th>\n","      <th>Misc Feature</th>\n","      <th>Misc Val</th>\n","      <th>Mo Sold</th>\n","      <th>Yr Sold</th>\n","      <th>Sale Type</th>\n","      <th>Sale Condition</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>526301100</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>141.0</td>\n","      <td>31770</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>215000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>526350040</td>\n","      <td>20</td>\n","      <td>RH</td>\n","      <td>80.0</td>\n","      <td>11622</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>MnPrv</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>105000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>526351010</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>81.0</td>\n","      <td>14267</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Gar2</td>\n","      <td>12500</td>\n","      <td>6</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>172000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>526353030</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>93.0</td>\n","      <td>11160</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>244000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>527105010</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>74.0</td>\n","      <td>13830</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>MnPrv</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>189900</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 82 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90fe20a4-35ad-4843-9fc8-e7721d0eb239')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-90fe20a4-35ad-4843-9fc8-e7721d0eb239 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-90fe20a4-35ad-4843-9fc8-e7721d0eb239');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["from sklearn.compose import make_column_transformer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","ct = make_column_transformer(\n","    (StandardScaler(), [\"Gr Liv Area\", \"Bedroom AbvGr\", \"Full Bath\"]),\n","    (OneHotEncoder(handle_unknown=\"ignore\"), [\"Neighborhood\", \"Bldg Type\"]),\n","    remainder=\"drop\"\n",")\n","\n","from sklearn.pipeline import make_pipeline\n","from sklearn.neighbors import KNeighborsRegressor\n","\n","pipeline = make_pipeline(\n","    ct,\n","    KNeighborsRegressor(n_neighbors=10)\n",")\n","\n","X_train = ames[[\"Gr Liv Area\", \"Bedroom AbvGr\", \"Full Bath\", \"Neighborhood\", \"Bldg Type\"]]\n","y_train = ames[\"SalePrice\"]\n","\n","scores = cross_val_score(pipeline,\n","                         X=X_train,\n","                         y=y_train,\n","                         scoring=\"r2\",\n","                         cv=10)\n","scores.mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULPzTFgl0jaF","executionInfo":{"status":"ok","timestamp":1653526096833,"user_tz":420,"elapsed":956,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"666af071-e382-4f89-f3fe-190e1dcbc47e"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7383048240888024"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"2QGFzFQ9r_p-"},"source":["2\\. Using the Tips data set (http://dlsun.github.io/pods/data/tips.csv ), train a $k$-nearest neighbors regression model to predict the tip, for several different values of $k$. Estimate the test MAE of each model and make a graph showing this test error as a function of $k$. How does it compare to the graph of the training MAE?"]},{"cell_type":"code","source":["tips = pd.read_csv(\"http://dlsun.github.io/pods/data/tips.csv\")\n","tips.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"mMs1cVK30iz9","executionInfo":{"status":"ok","timestamp":1653526131619,"user_tz":420,"elapsed":309,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"6f575435-b9c2-4624-cf7e-2dc52a1bf6d2"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   total_bill   tip     sex smoker  day    time  size\n","0       16.99  1.01  Female     No  Sun  Dinner     2\n","1       10.34  1.66    Male     No  Sun  Dinner     3\n","2       21.01  3.50    Male     No  Sun  Dinner     3\n","3       23.68  3.31    Male     No  Sun  Dinner     2\n","4       24.59  3.61  Female     No  Sun  Dinner     4"],"text/html":["\n","  <div id=\"df-4554ffcf-da7b-4f4e-ac01-828d54806ba4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>total_bill</th>\n","      <th>tip</th>\n","      <th>sex</th>\n","      <th>smoker</th>\n","      <th>day</th>\n","      <th>time</th>\n","      <th>size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>16.99</td>\n","      <td>1.01</td>\n","      <td>Female</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10.34</td>\n","      <td>1.66</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>21.01</td>\n","      <td>3.50</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>23.68</td>\n","      <td>3.31</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24.59</td>\n","      <td>3.61</td>\n","      <td>Female</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4554ffcf-da7b-4f4e-ac01-828d54806ba4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4554ffcf-da7b-4f4e-ac01-828d54806ba4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4554ffcf-da7b-4f4e-ac01-828d54806ba4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["ct = make_column_transformer(\n","    (OneHotEncoder(), [\"sex\", \"day\"]),\n","    (StandardScaler(), [\"total_bill\", \"size\"]),\n","    remainder=\"drop\"\n",")\n","\n","X_train = tips[[\"total_bill\", \"size\", \"sex\", \"day\"]]\n","y_train = tips[\"tip\"]"],"metadata":{"id":"2fydBOUl1nFl","executionInfo":{"status":"ok","timestamp":1653526197388,"user_tz":420,"elapsed":129,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","\n","maes = {}\n","for k in range(1, 20):\n","  pipeline = make_pipeline(\n","      ct,\n","      KNeighborsRegressor(n_neighbors=k)\n","  )\n","\n","  scores = cross_val_score(pipeline,\n","                           X=X_train,\n","                           y=y_train,\n","                           scoring=\"neg_mean_absolute_error\",\n","                           cv=10)\n","  \n","  maes[k] = -scores.mean()"],"metadata":{"id":"8btVEF4c13MF","executionInfo":{"status":"ok","timestamp":1653526365889,"user_tz":420,"elapsed":4591,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["pd.Series(maes).plot.line()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"AJTpfui92Mt1","executionInfo":{"status":"ok","timestamp":1653526510376,"user_tz":420,"elapsed":382,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"dde9fcb8-7e76-4ede-bf08-4829800c7722"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f458e2956d0>"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Copy of 5.5 Estimating the Test Error.ipynb","provenance":[{"file_id":"https://github.com/dlsun/pods/blob/master/05-Regression-Models/5.5%20Estimating%20the%20Test%20Error.ipynb","timestamp":1653523628001}]}},"nbformat":4,"nbformat_minor":0}