{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Copy of DATA 301 Lab 4B","provenance":[{"file_id":"14LmF5skBeQCBaD8Eq8ykJUWhZbjnMbMU","timestamp":1651605531286},{"file_id":"1p025hYX_zJp-wBlAfe0PcfTbLYk96Yuw","timestamp":1651515961124}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ByynuurZOPFd"},"source":["# Song Lyrics Generator\n","\n","In this lab, you will scrape a website to get lyrics of songs by your favorite artist. Then, you will train a model called a Markov chain on these lyrics so that you can generate a song in the style of your favorite artist.\n","\n","# Question 1. Scraping Song Lyrics\n","\n","Find a web site that has lyrics for several songs by your favorite artist. Scrape the lyrics into a Python list called `lyrics`, where each element of the list represents the lyrics of one song.\n","\n","**Tips:**\n","- Find a web page that has links to all of the songs, like [this one](https://www.azlyrics.com/s/stevemillerband.html). [_Note:_ It appears that `azlyrics.com` blocks web scraping, so you may have to find a different lyrics web site.] Then, you can scrape this page, extract the hyperlinks, and issue new HTTP requests to each hyperlink to get each song. \n","- Use `time.sleep()` to stagger your HTTP requests so that you do not get banned by the website for making too many requests."]},{"cell_type":"code","metadata":{"id":"7i7B9nidOPFg"},"source":["import requests\n","import time\n","\n","response = requests.get(\"http://www.songlyrics.com/lauv-lyrics/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbiq7kkEOPFl"},"source":["from bs4 import BeautifulSoup\n","soup = BeautifulSoup(response.content, \"html.parser\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lyrics = []\n","tables = soup.find_all(\"table\")\n","len(tables)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6PUSm7wfz-S","executionInfo":{"status":"ok","timestamp":1652165639110,"user_tz":420,"elapsed":2,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"a5459612-b40f-4dfc-9e1b-fa553a0c6b1a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"qvRlrVnKOPFp"},"source":["table = tables[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for song in table.find_all(\"a\", href=True):\n","  link = song[\"href\"]\n","\n","  response2 = requests.get(link)\n","  time.sleep(0.5)\n","  \n","  soup2 = BeautifulSoup(response2.text, \"html.parser\")\n","  lyrics.append(soup2.find_all(id = \"songLyricsDiv\")[0].text)"],"metadata":{"id":"TMafjkp5j1Jk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print out the lyrics to the first song.\n","print(lyrics[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPBa7QnRkS-A","executionInfo":{"status":"ok","timestamp":1652165664546,"user_tz":420,"elapsed":19,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"bc8dcc9d-f5dd-4fa9-f841-15bbcf531087"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Remembering what you said, I'm laying alone in bed\r\n","Tryina wrap up this feeling, falling apart instead\n","\r\n","'Cause baby we hit the top\r\n","Sweeter than sugar rocks\r\n","Holding onto a moment\r\n","Let go, I'm falling off\n","\r\n","I just need a little of it,\r\n","Need a little not a lot to get into it. Oh\r\n","Keep calling me home\n","\r\n","Can we go back to adrenaline?\r\n","Can we go back to adrenaline?\r\n","Girl you know that we've been settling, settling\r\n","But I need to feel, need to feel it\r\n","Adrenaline\n","\r\n","Remembering all those nights\r\n","With your body straight to the sky\r\n","Work me until the morning\r\n","Fall asleep half past nine (am)\n","\r\n","So crazy in love\r\n","Enough was never enough\r\n","Tell me our touch ain't dull now\r\n","Tell me our touch ain't dull now\n","\r\n","And I don't know where the ceiling is anymore\r\n","No I don't know where the feeling is anymore\n"]}]},{"cell_type":"markdown","metadata":{"id":"b9MbbohNOPFt"},"source":["`pickle` is a Python library that serializes Python objects to disk so that you can load them in later."]},{"cell_type":"code","metadata":{"id":"nQI-4UeqOPFu"},"source":["import pickle\n","pickle.dump(lyrics, open(\"lyrics.pkl\", \"wb\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o4ddDff6OPFx"},"source":["# Question 2. Unigram Markov Chain Model\n","\n","You will build a Markov chain for the artist whose lyrics you scraped in Question 1. Your model will process the lyrics and store the word transitions for that artist. The transitions will be stored in a dict called `chain`, which maps each word to a list of \"next\" words.\n","\n","For example, if your song was [\"The Joker\" by the Steve Miller Band](https://www.youtube.com/watch?v=dV3AziKTBUo), `chain` might look as follows:\n","\n","```\n","chain = {\n","    \"some\": [\"people\", \"call\", \"people\"],\n","    \"call\": [\"me\", \"me\", \"me\"],\n","    \"the\": [\"space\", \"gangster\", \"pompitous\", ...],\n","    \"me\": [\"the\", \"the\", \"Maurice\"],\n","    ...\n","}\n","```\n","\n","Besides words, you should include a few additional states in your Markov chain. You should have `\"<START>\"` and `\"<END>\"` states so that we can keep track of how songs are likely to begin and end. You should also include a state called `\"<N>\"` to denote line breaks so that you can keep track of where lines begin and end. It is up to you whether you want to include normalize case and strip punctuation.\n","\n","So for example, for [\"The Joker\"](https://www.azlyrics.com/lyrics/stevemillerband/thejoker.html), you would add the following to your chain:\n","\n","```\n","chain = {\n","    \"<START>\": [\"Some\", ...],\n","    \"Some\": [\"people\", ...],\n","    \"people\": [\"call\", ...],\n","    \"call\": [\"me\", ...],\n","    \"me\": [\"the\", ...],\n","    \"the\": [\"space\", ...],\n","    \"space\": [\"cowboy,\", ...],\n","    \"cowboy,\": [\"yeah\", ...],\n","    \"yeah\": [\"<N>\", ...],\n","    \"<N>\": [\"Some\", ..., \"Come\"],\n","    ...,\n","    \"Come\": [\"on\", ...],\n","    \"on\": [\"baby\", ...],\n","    \"baby\": [\"and\", ...],\n","    \"and\": [\"I'll\", ...],\n","    \"I'll\": [\"show\", ...],\n","    \"show\": [\"you\", ...],\n","    \"you\": [\"a\", ...],\n","    \"a\": [\"good\", ...],\n","    \"good\": [\"time\", ...],\n","    \"time\": [\"<END>\", ...],\n","}\n","```\n","\n","Your chain will be trained on not just one song, but by all songs by your artist."]},{"cell_type":"code","source":["import re\n","from collections import Counter\n","\n","def get_bigrams(list_words):\n","  return zip(list_words, list_words[1:])"],"metadata":{"id":"-Pv51venkwRY"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5P9Bsg6pOPFy"},"source":["def train_markov_chain(lyrics):\n","    \"\"\"\n","    Args:\n","      - lyrics: a list of strings, where each string represents\n","                the lyrics of one song by an artist.\n","    \n","    Returns:\n","      A dict that maps a single word (\"unigram\") to a list of\n","      words that follow that word, representing the Markov\n","      chain trained on the lyrics.\n","    \"\"\"\n","    chain = {\"<START>\": []}\n","    for lyric in lyrics:\n","        list_words = []\n","        words = re.sub(r'[^\\w\\s]', '', lyric).replace('\\n',' <N> ').split(\" \")\n","\n","        # make everything lowercase\n","        for word in words:\n","          if word == \"<N>\":\n","            list_words.append(word)\n","          elif word != \"\":\n","            list_words.append(word.lower())\n","        chain[\"<START>\"].append(list_words[0])\n","        \n","        chain[list_words[len(list_words)-1]] = []\n","        chain[list_words[len(list_words)-1]].append(\"<END>\")\n","        bigrams = get_bigrams(list_words)\n","        for item in bigrams:\n","          if chain.get(item[0]) is None:\n","            chain[item[0]] = []\n","          chain[item[0]].append(item[1])\n","    return chain"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewkgeMyQOPF2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652165664547,"user_tz":420,"elapsed":14,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"438ad0c6-6156-4896-aed2-fd013705b257"},"source":["# Load the pickled lyrics object that you created in Question 1.\n","import pickle\n","lyrics = pickle.load(open(\"lyrics.pkl\", \"rb\"))\n","\n","# Call the function you wrote above.\n","chain = train_markov_chain(lyrics)\n","\n","# What words tend to start a song (i.e., what words follow the <START> tag?)\n","print(chain[\"<START>\"])\n","\n","# What words tend to begin a line (i.e., what words follow the line break tag?)\n","print(chain[\"<N>\"][:20])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['remembering', 'like', 'i', 'smile', 'didnt', 'i', 'we', 'stick', 'i', 'i', 'i', 'i', 'like', 'its', 'we', 'running', 'running', 'doubt', 'to', 'stick', 'didnt', 'wait', 'didnt', 'like', 'ive', 'like', 'like', 'to', 'you', 'all', 'you', 'didnt']\n","['tryina', '\\r', 'cause', 'sweeter', 'holding', 'let', '\\r', 'i', 'need', 'keep', '\\r', 'can', 'can', 'girl', 'but', 'adrenaline', '\\r', 'remembering', 'with', 'work']\n"]}]},{"cell_type":"markdown","metadata":{"id":"CkdEbg7HOPF5"},"source":["Now, let's generate new lyrics using the Markov chain you constructed above. To do this, we'll begin at the `\"<START>\"` state and randomly sample a word from the list of words that follow `\"<START>\"`. Then, at each step, we'll randomly sample the next word from the list of words that followed each current word. We will continue this process until we sample the `\"<END>\"` state. This will give us the complete lyrics of a randomly generated song!\n","\n","You may find the `random.choice()` function helpful for this question."]},{"cell_type":"code","metadata":{"id":"CsFHxt0XOPF6"},"source":["import random\n","\n","def generate_new_lyrics(chain):\n","    \"\"\"\n","    Args:\n","      - chain: a dict representing the Markov chain,\n","               such as one generated by generate_new_lyrics()\n","    \n","    Returns:\n","      A string representing the randomly generated song.\n","    \"\"\"\n","    \n","    # a list for storing the generated words\n","    words = []\n","    # generate the first word\n","    word = random.choice(chain[\"<START>\"])\n","    \n","    while word != \"<END>\":\n","      words.append(word)\n","      word = random.choice(chain[word])\n","    \n","    # join the words together into a string with line breaks\n","    lyrics = \" \".join(words[:-1])\n","    return \"\\n\".join(lyrics.split(\"<N>\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmop55SGOPF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652165664732,"user_tz":420,"elapsed":198,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"92ca2eb8-9049-405d-fb85-924be65231b7"},"source":["print(generate_new_lyrics(chain))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["wait in the night \n"," you \n"," in the hours talking \n"," what night \n"," id rather lay let go that you \n"," i can reforget \n"," i can reforget \n"," and set them to not like dancing when i stay awhile stay \n"," i know who wrote the book on fire \n"," two more im feelin guilty \n"," \n"," wonder who i like me happy \n"," no one knows knows knows no other way \n"," work me better when im so far \n"," do anything to say that no good way yeah \n"," and set the book on mine \n"," cause anywhere we have this bed next to say \n"," put my all that \n"," when theres nothing quite wrong but it no other on fire \n"," and maybe im with wine on my coffee more hilarious misheard lyrics about to not to be watching i am running from the book on a wrap up the ceiling \n"," \n"," and\n"]}]},{"cell_type":"markdown","metadata":{"id":"CjwB8aiMOPGE"},"source":["# Question 3. Bigram Markov Chain Model\n","\n","Now you'll build a more complex Markov chain that uses the last _two_ words (or bigram) to predict the next word. Now your dict `chain` should map a _tuple_ of words to a list of words that appear after it.\n","\n","As before, you should also include tags that indicate the beginning and end of a song, as well as line breaks. That is, a tuple might contain tags like `\"<START>\"`, `\"<END>\"`, and `\"<N>\"`, in addition to regular words. So for example, for [\"The Joker\"](https://www.azlyrics.com/lyrics/stevemillerband/thejoker.html), you would add the following to your chain:\n","\n","```\n","chain = {\n","    (None, \"<START>\"): [\"Some\", ...],\n","    (\"<START>\", \"Some\"): [\"people\", ...],\n","    (\"Some\", \"people\"): [\"call\", ...],\n","    (\"people\", \"call\"): [\"me\", ...],\n","    (\"call\", \"me\"): [\"the\", ...],\n","    (\"me\", \"the\"): [\"space\", ...],\n","    (\"the\", \"space\"): [\"cowboy,\", ...],\n","    (\"space\", \"cowboy,\"): [\"yeah\", ...],\n","    (\"cowboy,\", \"yeah\"): [\"<N>\", ...],\n","    (\"yeah\", \"<N>\"): [\"Some\", ...],\n","    (\"time\", \"<N>\"): [\"Come\"],\n","    ...,\n","    (\"<N>\", \"Come\"): [\"on\", ...],\n","    (\"Come\", \"on\"): [\"baby\", ...],\n","    (\"on\", \"baby\"): [\"and\", ...],\n","    (\"baby\", \"and\"): [\"I'll\", ...],\n","    (\"and\", \"I'll\"): [\"show\", ...],\n","    (\"I'll\", \"show\"): [\"you\", ...],\n","    (\"show\", \"you\"): [\"a\", ...],\n","    (\"you\", \"a\"): [\"good\", ...],\n","    (\"a\", \"good\"): [\"time\", ...],\n","    (\"good\", \"time\"): [\"<END>\", ...],\n","}\n","```"]},{"cell_type":"code","metadata":{"id":"sQQf5qfLOPGF"},"source":["def train_markov_chain(lyrics):\n","    \"\"\"\n","    Args:\n","      - lyrics: a list of strings, where each string represents\n","                the lyrics of one song by an artist.\n","    \n","    Returns:\n","      A dict that maps a tuple of 2 words (\"bigram\") to a list of\n","      words that follow that bigram, representing the Markov\n","      chain trained on the lyrics.\n","    \"\"\"\n","    chain = {(None, \"<START>\"): []}\n","    for lyric in lyrics:\n","        lines = lyric.replace('\\n', ' <N> ').split()\n","        bigram = (None, \"<START>\")\n","        for word in lines:\n","            chain[bigram].append(word)\n","            bigram = (bigram[1], word)\n","            if bigram not in chain:\n","                chain[bigram] = []\n","        chain[bigram].append(\"<END>\")\n","    return chain"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpPtRfOxOPGI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652165664732,"user_tz":420,"elapsed":6,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"88454610-951b-4b3f-88c4-a66d80a95f82"},"source":["# Load the pickled lyrics object that you created in Question 1.\n","import pickle\n","lyrics = pickle.load(open(\"lyrics.pkl\", \"rb\"))\n","\n","# Call the function you wrote above.\n","chain = train_markov_chain(lyrics)\n","\n","# What words tend to start a song (i.e., what words follow the <START> tag?)\n","print(chain[(None, \"<START>\")])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Remembering', 'Like', 'I', 'Smile', \"Didn't\", 'I', 'We', 'Stick,', 'I', 'I', 'I', 'I', 'Like', \"It's\", 'We', 'Running', 'Running', 'Doubt,', 'To', 'Stick,', \"Didn't\", 'Wait', \"Didn't\", 'Like', \"I've\", 'Like', 'Like', 'To', 'You', 'All', 'You', \"Didn't\"]\n"]}]},{"cell_type":"markdown","metadata":{"id":"4rih6gnzOPGL"},"source":["Now, let's generate new lyrics using the Markov chain you constructed above. To do this, we'll begin at the `(None, \"<START>\")` state and randomly sample a word from the list of words that follow this bigram. Then, at each step, we'll randomly sample the next word from the list of words that followed the current bigram (i.e., the last two words). We will continue this process until we sample the `\"<END>\"` state. This will give us the complete lyrics of a randomly generated song!"]},{"cell_type":"code","metadata":{"id":"fmtEgsDoOPGM"},"source":["import random\n","\n","def generate_new_lyrics(chain):\n","    \"\"\"\n","    Args:\n","      - chain: a dict representing the Markov chain,\n","               such as one generated by generate_new_lyrics()\n","    \n","    Returns:\n","      A string representing the randomly generated song.\n","    \"\"\"\n","    \n","    # a list for storing the generated words\n","    words = []\n","    # generate the first word\n","    words.append(random.choice(chain[(None, \"<START>\")]))\n","    bigram = (\"<START>\", words[0])\n","    word = random.choice(chain[bigram])\n","\n","    while word != \"<END>\":\n","      words.append(word)\n","      bigram = (words[-2], words[-1])\n","      word = random.choice(chain[bigram])\n","      \n","    # join the words together into a string with line breaks\n","    lyrics = \" \".join(words[:-1])\n","    return \"\\n\".join(lyrics.split(\"<N>\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WPPTdLloOPGO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652165664733,"user_tz":420,"elapsed":4,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"4d8e5b4a-90a9-4b4a-a817-c3915abced6c"},"source":["print(generate_new_lyrics(chain))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I wanna feel you \n"," \n"," I'd have it no other way \n"," No one knows (knows, oh, oh) \n"," No one knows, knows, knows. \n"," Promoted Content \n"," This Game Can Train Your Brain to Think Strategically (No Joke!) \n"," featured video \n"," What's That Line? \n"," We all know \n"," That I thought we said we're good \n"," Yeah there's no good \n"," Yeah yeah yeah \n"," \n"," Lost in the rain \n"," I could be with someone, making me feel so far? \n"," \n"," Ooh why do we \n"," We fell from the first time, I'd stay for a long time cause \n"," I let you go, but baby, I'm gonna wear it \n"," I was driving you home in the rain, Paris in the rain \n"," We have to be, enemies, enemies? \n"," \n"," And I don't know how they're still in their frames \n"," There's never been a way to make this easy \n"," When there's nothing quite wrong but it don't feel right \n"," Either your head or your heart, you set the other on fire) \n"," Either your head or your heart, you set the other on fire \n"," No one knows, knows, knows. No one knows, knows, knows. No one knows (knows, oh, oh) \n"," \n"," Two more footsteps on the wood floor \n"," But that would be too easy, love \n"," Enough was never enough \n"," Tell me our touch ain't dull now \n"," I'm losing myself on the wood floor \n"," But the truth is \n"," You're like a rose \n"," Made it through all of your friends \n"," But that would be too easy, love \n"," I was driving you home in the middle of the night \n"," but I couldn't bring myself to say goodbye \n"," I was driving you home even if I go, even if I don't know where the feeling is anymore \n"," No one, no\n"]}]},{"cell_type":"markdown","metadata":{"id":"RUEJzOtnOPGR"},"source":["# Question 4. Analysis\n","\n","Compare the quality of the lyrics generated by the unigram model (in Question 2) and the bigram model (in Question 3). Which model seems to generate more reasonable lyrics? Can you explain why? What do you see as the advantages and disadvantages of each model?"]},{"cell_type":"markdown","metadata":{"id":"8k2Hym0UOPGS"},"source":["**The unigram model keeps words independent of previous words, so each word does not carry much meaning in the context of the lyrics. The bigram model seems to generate more reasonable lyrics because it takes the data in pairs, so the chance of having lyrics that make sense together are higher compared to the unigram model. Also, since the bigram model has information about the previous word, this format helps to put the word in context. An advantage of the unigram model is that it prints independent values. A disadvantage of the unigram model is that it does not provide context. An advantage of the bigram model is that it provides pairs of data and context. A disadvantage of the bigram model is that if there is not a lot of data, the model is not very useful.**"]},{"cell_type":"markdown","metadata":{"id":"bJYlXhArOPGT"},"source":["## Submission Instructions\n","\n","- Restart this notebook and run the cells from beginning to end:\n","  - Go to Runtime > Restart and Run All.\n","- Download the notebook:\n","  - Go to File > Download > Download .ipynb.\n","- Submit your notebook file to the assignment on Canvas.\n"]}]}
