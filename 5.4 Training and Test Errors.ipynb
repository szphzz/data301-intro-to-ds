{"cells":[{"cell_type":"markdown","metadata":{"id":"ORXhqwlEr_PK"},"source":["# 5.4 Training and Test Errors\n","\n","So far, we have fit regression models to data and obtained predictions from them, but we have not evaluated whether these predictions were any good. In this lesson, we will discuss different performance metrics that can be used to evaluate predictions from a machine learning model. These performance metrics can be calculated on training data or on test data."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"e75qWh_Vr_PP","executionInfo":{"status":"ok","timestamp":1653525293544,"user_tz":420,"elapsed":570,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# Extract the training data.\n","data_dir = \"https://dlsun.github.io/pods/data/\"\n","bordeaux_df = pd.read_csv(data_dir + \"bordeaux.csv\",\n","                          index_col=\"year\")\n","bordeaux_train = bordeaux_df.loc[:1980].copy()\n","bordeaux_train[\"log(price)\"] = np.log(bordeaux_train[\"price\"])"]},{"cell_type":"markdown","metadata":{"id":"AAavrZiyr_PR"},"source":["## Performance Metrics for Regression Models\n","\n","To evaluate the performance of a regression model, we check the predicted labels from the model against the true labels. Since the labels are quantitative, all of the performance metrics are based on the difference between each predicted label $\\hat y$ and the true label $y$. \n","\n","One way to make sense of these differences is to square each difference and average the squared differences. This measure of error is known as _mean squared error_ (or _MSE_, for short):\n","\n","$$ \n","\\begin{align*}\n","\\textrm{MSE} &= \\textrm{mean of } (y - \\hat y)^2.\n","\\end{align*}\n","$$ \n","\n","MSE is difficult to interpret because its units are the square of the units of the label. To make MSE more interpretable, it is common to take the _square root_ of the MSE to obtain the _root mean squared error_ (or _RMSE_, for short):\n","\n","$$ \n","\\begin{align*}\n","\\textrm{RMSE} &= \\sqrt{\\textrm{MSE}}.\n","\\end{align*}\n","$$ \n","\n","The RMSE measures how off a \"typical\" prediction is. Notice that this reasoning is exactly the same reasoning that we used in Chapter 3 when we defined the standard deviation as the square root of the variance.\n","\n","Another common measure of error is the _mean absolute error_ (or _MAE_, for short):\n","\n","$$ \n","\\begin{align*}\n","\\textrm{MAE} &= \\textrm{mean of } |y - \\hat y|.\n","\\end{align*}\n","$$ \n","\n","Like the RMSE, the MAE measures how off a \"typical\" prediction is. \n","\n","MSE, RMSE, and MAE are all error metrics; we want them to be as small as possible. There are also performance metrics that we seek to maximize. One example is $R^2$, also known as the _coefficient of determination_:\n","\n","\\begin{align*}\n","R^2 &= 1 - \\frac{\\text{mean of } (y - \\hat y)^2}{\\text{mean of } (y - \\bar y)^2}.\n","\\end{align*}\n","\n","Notice that the denominator, $\\text{mean of } (y - \\bar y)^2$, is just the variance of the label $y$. So the interpretation of $\\frac{\\text{mean of } (y - \\hat y)^2}{\\text{mean of } (y - \\bar y)^2}$ is the fraction of the variance in the label $y$ that is \"left over\" after we fit the regression model. Therefore, $R^2$ can be interpreted as the fraction of variance that is explained by the regression model. It cannot be greater than $1.0$, but it can sometimes be negative if the regression model is worse than useless.\n","\n","These are just some of the performance metrics that are used to evaluate regression models. For more, refer to the [scikit-learn documentation on regression metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)."]},{"cell_type":"markdown","metadata":{"id":"fSB_0yp1r_PS"},"source":["## Training Error\n","\n","To calculate the performance metrics above, we need data where the true labels are known. Where do we find such data? One natural source of labeled data is the training data, since we needed the true labels to be able to train a model.\n","\n","For a $k$-nearest neighbors model, the training data is the data from which the $k$-nearest neighbors are selected. So to calculate the training RMSE, we do the following:\n","\n","For each observation in the training data:\n","1. Find its $k$-nearest neighbors in the training data.\n","2. Average the labels of the $k$-nearest neighbors to obtain the predicted label.\n","3. Compare the predicted label to the true label.\n","\n","At this point, we can average the square of these differences to obtain the MSE or average their absolute values to obtain the MAE.\n","\n","Let's calculate the training MSE for the 5-nearest neighbors model that we fit in Chapter 5.2."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"h5EZxvo_r_PT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525298410,"user_tz":420,"elapsed":1580,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"d4fc690b-b393-40e0-a78d-09b42b516116"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('standardscaler', StandardScaler()),\n","                ('kneighborsregressor', KNeighborsRegressor())])"]},"metadata":{},"execution_count":2}],"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.pipeline import make_pipeline\n","\n","X_train = bordeaux_train[[\"win\", \"summer\"]]\n","y_train = bordeaux_train[\"log(price)\"]\n","\n","pipeline = make_pipeline(\n","          StandardScaler(),\n","          KNeighborsRegressor(n_neighbors=5)\n",")\n","\n","pipeline.fit(X=X_train, y=y_train)"]},{"cell_type":"markdown","metadata":{"id":"U1iq37Z7r_PU"},"source":["To calculate the training error, we need its predictions on the training data."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YdOI6JMtr_PU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525300005,"user_tz":420,"elapsed":151,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"d48be09a-a43b-4771-b56b-6c20b3b190d9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3.56069882, 3.38240361, 3.66085388, 2.70065469, 2.77198968,\n","       3.4843538 , 3.19493478, 3.76968555, 3.25353221, 2.5331913 ,\n","       3.4843538 , 2.51412926, 3.19493478, 3.08407263, 2.56202526,\n","       2.951578  , 3.32169799, 3.33549657, 2.6527587 , 3.4843538 ,\n","       2.56202526, 3.29634765, 3.4843538 , 2.86435018, 2.86435018,\n","       3.08407263, 2.6316866 ])"]},"metadata":{},"execution_count":3}],"source":["# Calculate the model predictions on the training data.\n","y_train_ = pipeline.predict(X=X_train)\n","y_train_"]},{"cell_type":"markdown","metadata":{"id":"vAtj-2Shr_PV"},"source":["Finally, we compare the predictions `y_train_` (note the trailing underscore) to the true labels `y_train`, which are known, since this is the training data."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6tXiJPzZr_PW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525301873,"user_tz":420,"elapsed":140,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"27967e3e-8315-4eb9-a05e-12dfd8871dac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.16338631596342398"]},"metadata":{},"execution_count":4}],"source":["# Calculate the mean-squared error.\n","mse = ((y_train - y_train_) ** 2).mean()\n","mse"]},{"cell_type":"markdown","metadata":{"id":"T1V7jY8Ir_PW"},"source":["We could have also used a scikit-learn function to calculate mean-squared error. The scikit-learn functions for the performance metrics discussed in this chapter are shown in the table below. All of these functions take a 1D-array of the true labels as the first parameter and a 1D-array of the predicted labels as the second.\n","\n","| Metric | Function Name |\n","|--------|---------------|\n","| MSE | `mean_squared_error` |\n","| MAE | `mean_absolute_error` |\n","| $R^2$ | `r2_score` |"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"PP85XlIkr_PX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525304015,"user_tz":420,"elapsed":127,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"0fbe78fe-bf38-4923-d646-1fbfdf917daa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.16338631596342398"]},"metadata":{},"execution_count":5}],"source":["from sklearn.metrics import mean_squared_error\n","mean_squared_error(y_train, y_train_)"]},{"cell_type":"markdown","metadata":{"id":"JHOXW172r_PX"},"source":["To obtain a measure of error that is more interpretable, we can take the square root to obtain the RMSE."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"fFrOLUOBr_PY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525305238,"user_tz":420,"elapsed":122,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"131b8e6b-8210-4e63-c1d9-e97bb17e0fbc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4042107321230152"]},"metadata":{},"execution_count":6}],"source":["rmse = np.sqrt(mse)\n","rmse"]},{"cell_type":"markdown","metadata":{"id":"PoqtvlTWr_PY"},"source":["The RMSE says that the model's predictions are off by about 0.4 on average. This is not too bad, since vintage quality ranges from 2.0 to 5.0."]},{"cell_type":"markdown","metadata":{"id":"UD3EQzHyr_PZ"},"source":["## Overfitting and Test Error\n","\n","Training error is not a great measure of the quality of a model. To see why, consider a 1-nearest neighbor regression model. Before you read on, can you guess what the training error of a 1-nearest neighbor regression model will be?"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Xo0I6MNnr_PZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653525306810,"user_tz":420,"elapsed":135,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"3473d16c-2bf4-43d6-ae4d-8678994c59df"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{},"execution_count":7}],"source":["# Fit a 1-nearest neighbors model.\n","model = KNeighborsRegressor(n_neighbors=1)\n","model.fit(X_train, y_train)\n","\n","# Calculate the model predictions on the training data.\n","y_train_ = model.predict(X_train)\n","\n","# Calculate the MSE\n","mean_squared_error(y_train, y_train_)"]},{"cell_type":"markdown","metadata":{"id":"PR97EEBmr_Pa"},"source":["The training error of this model seems too good to be true. Can our model really have an error of $0.0$? The reason, of course, is that the nearest neighbor to any observation in the training data is the observation itself!\n","\n","Ultimately, the goal of a machine learning model is to make predictions on *future* data. Therein lies the problem with training error. Training error measures how well a model does on the current data. It is possible to build a model that _overfits_ to the training data---that is, a model that fits so well to the current data that it does poorly on future data.\n","\n","For example, consider fitting two different models to the 10 training observations shown below. The model represented by the red line actually passes through every observation (that is, its training error is zero). However, most people would prefer the model represented by the blue line. If one had to make a prediction for the label when $x = 0.8$, the value of the blue line is intuitively more plausible than the value of the red line, which is out of step with the nearby points.\n","\n","![](https://github.com/dlsun/pods/blob/master/05-Regression-Models/overfitting.png?raw=1)\n","\n","To make a case for the blue model using mean-squared error, we would need future, or test, data. The red model is as good as it gets when it comes to the training data.\n","\n","The prediction error on future data is also known as _test error_. But to calculate the test error, we need _labeled_ future data. In many applications, data is hard to collect and _labeled_ data is harder still. In the next lesson, we discuss strategies for approximating the test error using only the training data that we aleady have."]},{"cell_type":"markdown","metadata":{"id":"9qQxlaN8r_Pa"},"source":["# Exercises"]},{"cell_type":"markdown","metadata":{"id":"lgAq5ifor_Pa"},"source":["1\\. Calculate the training coefficient of determination ($R^2$) of the $10$-nearest neighbors regression model that we fit in the lesson of Chapter 5.3 to the Ames housing data set (http://dlsun.github.io/pods/data/AmesHousing.txt )."]},{"cell_type":"code","source":["ames = pd.read_table(\"http://dlsun.github.io/pods/data/AmesHousing.txt\")\n","ames.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"gH533pMmygm0","executionInfo":{"status":"ok","timestamp":1653525342296,"user_tz":420,"elapsed":583,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"5005302d-f285-452e-ba80-ebbe7655cf0e"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n","0      1  526301100           20        RL         141.0     31770   Pave   \n","1      2  526350040           20        RH          80.0     11622   Pave   \n","2      3  526351010           20        RL          81.0     14267   Pave   \n","3      4  526353030           20        RL          93.0     11160   Pave   \n","4      5  527105010           60        RL          74.0     13830   Pave   \n","\n","  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n","0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n","1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n","2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n","3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n","4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n","\n","  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n","0        0       5    2010       WD           Normal     215000  \n","1        0       6    2010       WD           Normal     105000  \n","2    12500       6    2010       WD           Normal     172000  \n","3        0       4    2010       WD           Normal     244000  \n","4        0       3    2010       WD           Normal     189900  \n","\n","[5 rows x 82 columns]"],"text/html":["\n","  <div id=\"df-3631900b-63db-4099-a120-5bb89ee1657f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Order</th>\n","      <th>PID</th>\n","      <th>MS SubClass</th>\n","      <th>MS Zoning</th>\n","      <th>Lot Frontage</th>\n","      <th>Lot Area</th>\n","      <th>Street</th>\n","      <th>Alley</th>\n","      <th>Lot Shape</th>\n","      <th>Land Contour</th>\n","      <th>...</th>\n","      <th>Pool Area</th>\n","      <th>Pool QC</th>\n","      <th>Fence</th>\n","      <th>Misc Feature</th>\n","      <th>Misc Val</th>\n","      <th>Mo Sold</th>\n","      <th>Yr Sold</th>\n","      <th>Sale Type</th>\n","      <th>Sale Condition</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>526301100</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>141.0</td>\n","      <td>31770</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>215000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>526350040</td>\n","      <td>20</td>\n","      <td>RH</td>\n","      <td>80.0</td>\n","      <td>11622</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>MnPrv</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>105000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>526351010</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>81.0</td>\n","      <td>14267</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Gar2</td>\n","      <td>12500</td>\n","      <td>6</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>172000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>526353030</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>93.0</td>\n","      <td>11160</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>244000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>527105010</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>74.0</td>\n","      <td>13830</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>MnPrv</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>189900</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 82 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3631900b-63db-4099-a120-5bb89ee1657f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3631900b-63db-4099-a120-5bb89ee1657f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3631900b-63db-4099-a120-5bb89ee1657f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from sklearn.compose import make_column_transformer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","ct = make_column_transformer(\n","    (StandardScaler(), [\"Gr Liv Area\", \"Bedroom AbvGr\", \"Full Bath\"]),\n","    (OneHotEncoder(), [\"Neighborhood\", \"Bldg Type\"]),\n","    remainder=\"drop\"\n",")\n","\n","from sklearn.pipeline import make_pipeline\n","from sklearn.neighbors import KNeighborsRegressor\n","\n","pipeline = make_pipeline(\n","    ct,\n","    KNeighborsRegressor(n_neighbors=10)\n",")\n","\n","X_train = ames[[\"Gr Liv Area\", \"Bedroom AbvGr\", \"Full Bath\", \"Neighborhood\", \"Bldg Type\"]]\n","y_train = ames[\"SalePrice\"]\n","\n","pipeline.fit(X=X_train, y=y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YO2MuDSwynGL","executionInfo":{"status":"ok","timestamp":1653525545338,"user_tz":420,"elapsed":182,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"e4bf5722-ab40-46f4-87f0-1d23e001fd10"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('columntransformer',\n","                 ColumnTransformer(transformers=[('standardscaler',\n","                                                  StandardScaler(),\n","                                                  ['Gr Liv Area',\n","                                                   'Bedroom AbvGr',\n","                                                   'Full Bath']),\n","                                                 ('onehotencoder',\n","                                                  OneHotEncoder(),\n","                                                  ['Neighborhood',\n","                                                   'Bldg Type'])])),\n","                ('kneighborsregressor', KNeighborsRegressor(n_neighbors=10))])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["from sklearn.metrics import r2_score\n","\n","y_pred = pipeline.predict(X_train)\n","r2_score(y_train, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTIJMmNIzZjN","executionInfo":{"status":"ok","timestamp":1653525586131,"user_tz":420,"elapsed":718,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"372abbb6-7e79-499b-a38f-2b78a930981d"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8208718803145867"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"wZfVbqLqr_Pb"},"source":["2\\. Using the Tips data set (http://dlsun.github.io/pods/data/tips.csv ), train $k$-nearest neighbors regression models to predict the tip, for several different values of $k$. Calculate the training MAE of each model and make a graph showing this training error as a function of $k$."]},{"cell_type":"code","source":["tips = pd.read_csv(\"http://dlsun.github.io/pods/data/tips.csv\")\n","tips.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"K6MngEoNzi2c","executionInfo":{"status":"ok","timestamp":1653525615816,"user_tz":420,"elapsed":310,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"a16723d2-bf5f-4224-a0b4-bdb994343a28"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   total_bill   tip     sex smoker  day    time  size\n","0       16.99  1.01  Female     No  Sun  Dinner     2\n","1       10.34  1.66    Male     No  Sun  Dinner     3\n","2       21.01  3.50    Male     No  Sun  Dinner     3\n","3       23.68  3.31    Male     No  Sun  Dinner     2\n","4       24.59  3.61  Female     No  Sun  Dinner     4"],"text/html":["\n","  <div id=\"df-f32677dd-b85a-4e0f-9bd1-25aee807847b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>total_bill</th>\n","      <th>tip</th>\n","      <th>sex</th>\n","      <th>smoker</th>\n","      <th>day</th>\n","      <th>time</th>\n","      <th>size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>16.99</td>\n","      <td>1.01</td>\n","      <td>Female</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10.34</td>\n","      <td>1.66</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>21.01</td>\n","      <td>3.50</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>23.68</td>\n","      <td>3.31</td>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24.59</td>\n","      <td>3.61</td>\n","      <td>Female</td>\n","      <td>No</td>\n","      <td>Sun</td>\n","      <td>Dinner</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f32677dd-b85a-4e0f-9bd1-25aee807847b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f32677dd-b85a-4e0f-9bd1-25aee807847b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f32677dd-b85a-4e0f-9bd1-25aee807847b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["ct = make_column_transformer(\n","    (OneHotEncoder(), [\"sex\", \"day\"]),\n","    (StandardScaler(), [\"total_bill\", \"size\"]),\n","    remainder=\"drop\"\n",")\n","\n","X_train = tips[[\"total_bill\", \"size\", \"sex\", \"day\"]]\n","y_train = tips[\"tip\"]"],"metadata":{"id":"E5Aqa4mJzpJz","executionInfo":{"status":"ok","timestamp":1653525685662,"user_tz":420,"elapsed":122,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","\n","maes = {}\n","for k in range (1, 20):\n","  pipeline = make_pipeline(\n","      ct,\n","      KNeighborsRegressor(n_neighbors=k)\n","  )\n","\n","  pipeline.fit(X=X_train,\n","               y=y_train)\n","  \n","  y_pred = pipeline.predict(X_train)\n","  \n","  maes[k] = mean_absolute_error(y_train, y_pred)"],"metadata":{"id":"l7HHIkeVz4ua","executionInfo":{"status":"ok","timestamp":1653525777147,"user_tz":420,"elapsed":576,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["pd.Series(maes).plot.line()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"kI30e6s20Qek","executionInfo":{"status":"ok","timestamp":1653525790709,"user_tz":420,"elapsed":570,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"cfdc5bbe-2e83-48e2-cd08-7af37f024999"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f2954fde7d0>"]},"metadata":{},"execution_count":15},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Copy of 5.4 Training and Test Errors.ipynb","provenance":[{"file_id":"https://github.com/dlsun/pods/blob/master/05-Regression-Models/5.4%20Training%20and%20Test%20Errors.ipynb","timestamp":1653523612189}]}},"nbformat":4,"nbformat_minor":0}